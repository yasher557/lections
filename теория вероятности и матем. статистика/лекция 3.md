#2024/09/30
# асимптотические формулы

## теоремы Лапласа.

Пользоваться формулой Бернулли при больших значениях n затруднительно. Приведём асимптотическую формулу, которая позволяет приближённо найти вероятность появления события ровно k раз в n испытаниях, если число испытаний достаточно велико.

Формула Пуассона. Если вероятность P наступления события A в каждом событии постоянно, но близка к нулю, число независимых испытаний n достаточно велико, а произведение n и p, равное lambda сохраняет постоянное значение, то вероятность Pₙ(k), что в n независимых испытаний событие A наступит приблизительно k раз, равна: $$ P_n(k) ≈ \frac{\lambda ^k \cdot e^{-\lambda}}{k!} $$
	**==пример:==**
	.
	**задание:** На склад везут 1000 графинов. Вероятность того, что 1 графин разобьётся, равна 0, 008. Какова вероятность того, что разобьётся 4 графина?
	.
	**решение:** $$ P_{1000} ≈ \frac{2^4 \cdot e^{-2}}{4!} = \frac{16}{24e^2} =\frac{2}{3e^2}$$

### Локальная теорема Лапласа

Если вероятность P в каждом испытании постоянна и P ≠ 0 и P ≠ 1, то вероятность Pₙ(k) того что в n (чем больше n, тем точнее) независимых испытаний событие A наступит приблизительно k раз, равна значению функции y: $$
\begin{multline} \\ 
	 P _ n(k) ≈ \frac{1}{\sqrt{npc}}\phi(x) \\
	 y = \frac{1}{\sqrt{npq}} \cdot \phi _ 1,\ \ \ \ где\ \phi (x) = \frac{1}{\sqrt{2 \pi}} \cdot c^{-\frac{x^2}{2}} \\
	 x = \frac{k - np}{\sqrt{npq}} \\
 \\ \end{multline} $$
### интегральная теорема Лапласа:

Если вероятность P в каждом испытании постоянна и P ≠ 0 и P ≠ 1, то вероятность Pₙ(k₁, k₂,) того, что событие A появится в n испытаниях не менее k₁ b не более k₂ раз, приблизительно равна: $$
\begin{multline} \\ 
	P _n(k_ 1,\ k _2) ≠ \phi(x_ 2) - \phi(x_1),\ где\ \ \ \ \phi(x) = \frac{1}{\sqrt{2 \pi}} = \int _ b^x e^{- \frac{t^2}{2}} dt  \\
	x _ 1 = \frac{k _ 1 - np}{\sqrt{npq}} \cdot \phi(-x) = - \phi (x)  \\
	x _ 2 = \frac{k_ 2 - np}{\sqrt{npq}}  \\
\\ \end{multline} $$
## случайные величины (СВ)

 Случайной называется величина, которая в результате опыта может принять то или иное возможное значение, неизвестное заранее, но обязательно одно. Случайные величины обозначаются большими буквами X, Y, Z, а их возможные значения маленькими x, y, z.

Непрерывной называют случайную величину (НСВ), которая может принимать все значения из некоторого конечного или бесконечного промежутка.

Для полного описания случайной величины необходимо знать не только возможные значения, но и вероятности. 


### дискретная случайная величина

Дискретной называется случайная величина, которая принимает отдельные изолированные возможные значения с определёнными вероятностями (ДСВ).

#### закон распределения вероятности дискретной случайной величины (ДСВ)

Законом Распределения ДСВ называется всякое соотношение устанавливающее связи между возможными значениями СВ и соответствующими вероятностями. $$ P(x = x_i) = pi,\ i= \overline{1,\ n}$$
Рассмотрим ДСВ(X) с возможными значениями x₁, x₂, ... xₙ, в результате опыта СВ примет одно и только одно из заданных значений, то есть произойдёт одно из совместных событий образующих полную группу вероятности: $$
\begin{multline} \\ 
	P (X = X _1) = P_ 1 +\ ...\ P(x = x _n) = P_ n \\
	т.е.\ \sum^n _{i = 1} P(x = x_ i) = \sum^n_{i = 1} pi = 1  \\
\\ \end{multline} $$
Закон распределения можно задать табличным (ряд распределения), графическим (рассматриваем таблицу как координаты точки) или аналитическим способами.

При решении практических задач важно знать лишь некоторые числовые параметры которые называют числовые характеристики случайной величины: характеристики положения, характеристики рассеяния.

#### числовые характеристики ДСВ:

1. математическое ожидание
	
	==Математическим ожиданием ДСВ== называют сумму произведений всех её возможных значений на их вероятности. Математическое ожидание приближённо равно (тем точнее, чем больше число испытаний) среднему арифметическому наблюдаемых значений случайной величины.
	
	**обозначение:** $$ M(x) \sum^n _{i = 1} x_ i \cdot p_i $$
	**свойства:** 
	1. M(c) = c
		математическое ожидание константы равно константе
	2. M(cx) = cM(x)
		постоянный множитель можно вынести
	3. M(xy) = M(x) ⋅ M(y)
		математическое ожидание произведения равно произведению математических ожиданий
	4. M(x + y) = M(x) + M(y)
		математическое ожидание суммы равно сумме математических ожиданий
	
	**теорема**: Математические ожидание M(x) числа появления события A в n независимых испытаниях равно произведению числа испытаний на вероятность появления события в каждом испытании: $$ M(x) = np $$
2. Мода
	
	==Модой ДСВ(X)== называется её значение, принимаемое с наибольшей вероятностью по сравнению с двумя соседними значениями. обозначается как M₀(X).
	
3. медиана
	
	==Медиана для ДСВ== обычно не определяется.
	
4. рассеяние (дисперсия)
	
	Для того, чтобы оценить как рассеяны возможные значения случайной величины вокруг её математического ожидания, пользуются числовой характеристикой, которую называют дисперсией.
	
	==Отклонением== называют разность между СВ и её математическим ожиданием.
		**обозначение:** $$
		\begin{multline} \\ 
			\overset{\circ}{X} = X - M(X) \\
			M(\overset{\circ}{X}) = 0 \\
		\\ \end{multline} $$
	
	==Дисперсией== называют математическое ожидание квадрата отклонения.
	
	 Дисперсия равна разности между математическим ожиданием квадрата СВ(X) и квадратом её математического ожидания: $$ D(X) = M(X^2) - M^2(X) $$
	**свойства:** 
	1. D(C) = 0
	2. D(CX) = C²D(X)
	3. D(X +- Y) = D(X) + D(Y)
	4. D(X + C) = D(X)
	5. D(XY) = M(X²)M(Y²) - M²(X) ⋅ M²(Y)
	
	**теорема:** Дисперсия числа появлений события A в n независимых испытаний, в каждом из которых вероятность  p появления события постоянна, равна произведению числа испытаний на вероятности появления и непоявления события в одном испытании.
	
5. среднее квадратическое отклонение
	
	==**Средним квадратическим отклонением**== СВ(X) называют квадратный корень из дисперсии.
	
	$$ G(X) = \sqrt{D(X)} $$
	**свойства:**
	1. G(C) = 0
	2. G(CX) = |C| ⋅ G(X)
	3. G(X + C) = G(X)
	4. D(X) = G²(X)

Для изучения свойств случайного явления, независимо от выбора масштаба измерения и положения центра группирования, исходную СВХ приводят к некоторому изменению вида: её центруют и нормируют . (СВГ) называется стандартной ___ величиной. $$
\begin{multline} \\ 
	 Z = \frac{X \cdot M(X)}{Q(X)} \\
	 притом:\ \ \ \ \ M(Z) = D;\ \ \ \ D(Z) = 1  \\
 \\ \end{multline} $$

#### начальный и центральный теоретические моменты

Математическое ожидание и дисперсия — частные случаи более общих понятий — моментов.

==Начальным моментом== порядка k СВ(X) величины X называют математическое ожидание Xᵏ:   $$
	\begin{multline} \\ 
	\nu _k = M(X^k) \\
	\nu _1 = M(X)  \\
	\nu _ 2 = M(X^2)  \\
	D(X) = \nu _2 - \nu _ 1^2\\
\\ \end{multline} $$
==Центральным моментом== порядка k СВ(X) величины X называют математическое ожидание величины (XM(X))ᵏ = Mₖ: $$
\begin{multline} \\ 
	M _1 = 0 \\
	M _ 2 = D(X) = \nu _ 2 - \nu _ 1 ^2 \\
	M _3 = \nu _ 3 - 3 \nu _1 \nu_ 2 + 2\nu _1^2\\
\\ \end{multline} $$

